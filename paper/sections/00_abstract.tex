\begin{abstract}
% TODO: Summarize the Low-Rank Hypothesis, the Metabolic Attack mechanism, 
% and the empirical finding (1B collapse vs. Quantization immunity).

We present a theoretical and empirical investigation of structural vulnerabilities in large language models, demonstrating that larger models exhibit increased fragility to metabolic attacks that induce spectral collapse. Our work establishes an inverse scaling law: as model size increases, vulnerability to attacks exploiting the Hessian null space increases dramatically. We show that a 1B parameter model suffers catastrophic rank reduction (26.4\%) while smaller models (70M-410M) remain relatively robust. Critically, we demonstrate that quantization acts as a thermodynamic shield, with 8-bit quantization reducing attack effectiveness by a factor of 70x. These findings have profound implications for AI safety and model architecture design.

% Key points to cover:
% - Low-Rank Hypothesis: Models operate in low-dimensional manifolds
% - Metabolic Attack: Exploits Adam's amplification of noise in null space directions
% - Empirical finding: 1B collapse (26.4%) vs Quantization immunity (0.3% at 8-bit)
\end{abstract}
