% Bibliography for NeuroEntropy Paper
% Key references for metabolic attacks, scaling laws, and related work

% Grounded on Google Scholar: We would add comments (in MLA format) to the references that are manually verified. 
% If there are multiple versions of the same reference, we would prefer to use the one published in the journal or conference.

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}
@comment{Manually verified: Adam, Kingma DP Ba J. "A method for stochastic optimization." arXiv preprint arXiv:1412.6980 1412.6 (2014).}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}
@comment{Manually verified: Kaplan, Jared, et al. "Scaling laws for neural language models." arXiv preprint arXiv:2001.08361 (2020).}

@inproceedings{biderman2023pythia,
  title={Pythia: A suite for analyzing large language models across training and scaling},
  author={Biderman, Stella and Schoelkopf, Hailey and Anthony, Quentin and Bradley, Herbie and O'Brien, Kyle and Hallahan, Eric and Khan, Mohammad Aflah and Purohit, Shivanshu and Prashanth, USVSN Sai and Raff, Edward and others},
  booktitle={International Conference on Machine Learning},
  publisher={PMLR},
  year={2023}
}
@comment{Manually verified: Biderman, Stella, et al. "Pythia: A suite for analyzing large language models across training and scaling, 2023." URL https://arxiv. org/abs/2304.01373 (2022).}
@comment{Manually verified: Biderman, Stella, et al. "Pythia: A suite for analyzing large language models across training and scaling." International Conference on Machine Learning. PMLR, 2023.}

@article{frantar2022gptq,
  title={GPTQ: Accurate post-training quantization for generative pre-trained transformers},
  author={Frantar, Elias and Ashkboos, Saleh and Hoefler, Torsten and Alistarh, Dan},
  journal={arXiv preprint arXiv:2210.17323},
  year={2022}
}
@comment{Manually verified: Frantar, Elias, et al. "Gptq: Accurate post-training quantization for generative pre-trained transformers." arXiv preprint arXiv:2210.17323 (2022).}

@article{dettmers2022gpt3int8,
  title={Gpt3. int8 (): 8-bit matrix multiplication for transformers at scale},
  author={Dettmers, Tim and Lewis, Mike and Belkada, Younes and Zettlemoyer, Luke},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={30318--30332},
  year={2022}
}
@comment{Manually verified: Dettmers, Tim, et al. "Gpt3. int8 (): 8-bit matrix multiplication for transformers at scale." Advances in neural information processing systems 35 (2022): 30318-30332.}

@article{pearlmutter1994fast,
  title={Fast exact multiplication by the Hessian},
  author={Pearlmutter, Barak A},
  journal={Neural computation},
  volume={6},
  number={1},
  pages={147--160},
  year={1994}
}
@comment{Manually verified: Pearlmutter, Barak A. "Fast exact multiplication by the Hessian." Neural computation 6.1 (1994): 147-160.}

@article{li2018hessian,
  title={Visualizing the loss landscape of neural nets},
  author={Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}
@comment{Manually verified: Li, Hao, et al. "Visualizing the loss landscape of neural nets." Advances in neural information processing systems 31 (2018).}

@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}
@comment{Manually verified: Goodfellow, Ian J., Jonathon Shlens, and Christian Szegedy. "Explaining and harnessing adversarial examples." arXiv preprint arXiv:1412.6572 (2014).}

@article{szegedy2013intriguing,
  title={Intriguing properties of neural networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  journal={arXiv preprint arXiv:1312.6199},
  year={2013}
}
@comment{Manually verified: Szegedy, Christian, et al. "Intriguing properties of neural networks." arXiv preprint arXiv:1312.6199 (2013).}

@article{zou2023universal,
  title={Universal and transferable adversarial attacks on aligned language models},
  author={Zou, Andy and Wang, Zifan and Kolter, J Zico and Fredrikson, Matt},
  journal={arXiv preprint arXiv:2307.15043},
  year={2023}
}
@comment{Manually verified: Zou, Andy, et al. "Universal and transferable adversarial attacks on aligned language models." arXiv preprint arXiv:2307.15043 (2023).}

@article{gu2019badnets,
  title={Badnets: Evaluating backdooring attacks on deep neural networks},
  author={Gu, Tianyu and Dolan-Gavitt, Brendan and Garg, Siddharth},
  journal={IEEE Access},
  volume={7},
  pages={47230--47244},
  year={2019}
}
@comment{Manually verified: Gu, Tianyu, et al. "Badnets: Evaluating backdooring attacks on deep neural networks." Ieee Access 7 (2019): 47230-47244.}
@comment{Manually verified: Gu, Tianyu, Brendan Dolan-Gavitt, and Siddharth Garg. "Badnets: Identifying vulnerabilities in the machine learning model supply chain." arXiv preprint arXiv:1708.06733 (2017).}

@inproceedings{shafahi2018poison,
  title={Poison frogs! targeted clean-label poisoning attacks on neural networks},
  author={Shafahi, Ali and Huang, W Ronny and Najibi, Mahyar and Suciu, Octavian and Studer, Christoph and Dumitras, Tudor and Goldstein, Tom},
  booktitle={Advances in neural information processing systems},
  volume={31},
  year={2018}
}
@comment{Manually verified: Shafahi, Ali, et al. "Poison frogs! targeted clean-label poisoning attacks on neural networks." Advances in neural information processing systems 31 (2018).}

@article{hubinger2024sleeper,
  title={Sleeper agents: Training deceptive LLMs that persist through safety training},
  author={Hubinger, Evan and Denison, Carson and Mu, Jesse and Lambert, Mike and Tong, Meg and MacDiarmid, Monte and Lanham, Tamera and Ziegler, Daniel M and Maxwell, Tim and Cheng, Newton and others},
  journal={arXiv preprint arXiv:2401.05566},
  year={2024}
}
@comment{Manually verified: Hubinger, Evan, et al. "Sleeper agents: Training deceptive llms that persist through safety training." arXiv preprint arXiv:2401.05566 (2024).}

@article{shumailov2023curse,
  title={The curse of recursion: Training on generated data makes models forget},
  author={Shumailov, Ilia and Shumaylov, Zakhar and Zhao, Yiren and Gal, Yarin and Papernot, Nicolas and Anderson, Ross},
  journal={arXiv preprint arXiv:2305.17493},
  year={2023}
}
@comment{Manually verified: Shumailov, Ilia, et al. "The curse of recursion: Training on generated data makes models forget." arXiv preprint arXiv:2305.17493 (2023).}

@article{shumailov2024ai,
  title={AI models collapse when trained on recursively generated data},
  author={Shumailov, Ilia and Shumaylov, Zakhar and Zhao, Yiren and Papernot, Nicolas and Anderson, Ross and Gal, Yarin},
  journal={Nature},
  volume={631},
  number={8022},
  pages={755--759},
  year={2024},
  publisher={Nature Publishing Group}
}
@comment{Manually verified: Shumailov, Ilia, et al. "AI models collapse when trained on recursively generated data." Nature 631.8022 (2024): 755-759.}

@article{thibeault2024lowrank,
  title={The low-rank hypothesis of complex systems},
  author={Thibeault, Vincent and Allard, Antoine and Desrosiers, Patrick},
  journal={Nature Physics},
  volume={20},
  number={3},
  pages={294--302},
  year={2024},
  publisher={Nature Publishing Group}
}
@comment{Manually verified: Thibeault, Vincent, Antoine Allard, and Patrick Desrosiers. "The low-rank hypothesis of complex systems." Nature Physics 20.2 (2024): 294-302.}

@article{xie2025mhc,
  title={mHC: Manifold-Constrained Hyper-Connections},
  author={Xie, Zhuowen and Wei, Yuxuan and Cao, Hao and others},
  journal={arXiv preprint arXiv:2512.24880},
  year={2025}
}
@comment{Manually verified: Xie, Zhenda, et al. "mhc: Manifold-constrained hyper-connections." arXiv preprint arXiv:2512.24880 (2025).}


% Add more references as needed
